{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14980edd-887f-4934-a8f6-5d638b39d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import chromedriver_autoinstaller\n",
    "from bs4 import BeautifulSoup\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Ensure ChromeDriver is installed\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# Set Chrome binary location (adjust if needed)\n",
    "chrome_path = \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n",
    "if not os.path.exists(chrome_path):\n",
    "    chrome_path = shutil.which(\"google-chrome\")\n",
    "\n",
    "# Goodreads list URL\n",
    "GOODREADS_URL = \"https://www.goodreads.com/list/show/264.Books_That_Everyone_Should_Read_At_Least_Once\"\n",
    "\n",
    "# Set up Selenium WebDriver options\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--window-size=1920x1080\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "if chrome_path:\n",
    "    options.binary_location = chrome_path\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "titles = []\n",
    "authors = []\n",
    "avg_ratings = []\n",
    "genres = []\n",
    "first_published_list = []\n",
    "\n",
    "books_scraped = 0\n",
    "page = 1\n",
    "\n",
    "while page <= 10:\n",
    "    print(f\"\\nðŸ”„ Scraping Page {page}...\\n\")\n",
    "    driver.get(f\"{GOODREADS_URL}?page={page}\")\n",
    "    try:\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"table.tableList tr\")))\n",
    "    except:\n",
    "        print(f\"Timeout waiting for books on page {page}. Retrying after delay...\")\n",
    "        time.sleep(random.uniform(5, 10))\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    book_rows = soup.select(\"tr[itemtype='http://schema.org/Book']\")\n",
    "\n",
    "    if not book_rows:\n",
    "        print(f\"No books found on page {page}. Ending scraping.\")\n",
    "        break\n",
    "\n",
    "    for row in book_rows:\n",
    "        title_tag = row.select_one(\"a.bookTitle\")\n",
    "        author_tag = row.select_one(\"a.authorName\")\n",
    "        rating_tag = row.select_one(\"span.minirating\")\n",
    "\n",
    "        title = title_tag.text.strip() if title_tag else \"\"\n",
    "        author = author_tag.text.strip() if author_tag else \"\"\n",
    "        avg_rating = rating_tag.text.strip().split(\" â€” \")[0] if rating_tag else \"\"\n",
    "\n",
    "        # Click into book detail page\n",
    "        book_url = f\"https://www.goodreads.com{title_tag['href']}\"\n",
    "        driver.get(book_url)\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "        book_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Genres\n",
    "        genre_tags = book_soup.select(\"a.bookPageGenreLink\")\n",
    "        top_genres = list(dict.fromkeys([g.text.strip() for g in genre_tags]))[:3]\n",
    "        genre_str = \", \".join(top_genres)\n",
    "\n",
    "        # First published\n",
    "        pub_info = book_soup.find(\"div\", id=\"details\")\n",
    "        if pub_info:\n",
    "            pub_text = pub_info.get_text(\" \", strip=True)\n",
    "            pub_split = [s for s in pub_text.split(\" \") if s.isdigit() and len(s) == 4]\n",
    "            first_pub = pub_split[0] if pub_split else \"Unknown\"\n",
    "        else:\n",
    "            first_pub = \"Unknown\"\n",
    "\n",
    "        titles.append(title)\n",
    "        authors.append(author)\n",
    "        avg_ratings.append(avg_rating)\n",
    "        genres.append(genre_str)\n",
    "        first_published_list.append(first_pub)\n",
    "\n",
    "        books_scraped += 1\n",
    "        print(f\"Scraped: {books_scraped} - {title}\")\n",
    "\n",
    "        driver.back()\n",
    "        time.sleep(random.uniform(1, 2))\n",
    "\n",
    "    print(f\"âœ… Finished Page {page}. Total books scraped so far: {books_scraped}\\n\")\n",
    "    page += 1\n",
    "    time.sleep(random.uniform(2, 4))\n",
    "\n",
    "# Close driver\n",
    "driver.quit()\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Author\": authors,\n",
    "    \"Average Rating\": avg_ratings,\n",
    "    \"Top 3 Genres\": genres,\n",
    "    \"First Published\": first_published_list\n",
    "})\n",
    "\n",
    "df.to_csv(\"goodreads_books.csv\", index=False)\n",
    "print(\"Scraping complete! Saved as goodreads_books.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbac6c2-a2de-42e7-9d2e-c05cc0f1ea7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
